{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Lab Assignment 03:"
      ],
      "metadata": {
        "id": "QTRAbgqM6_tM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Background and Data Dictionary\n",
        "\n",
        "In this lab assignment, you will analyze data provided on Canvas under the file name \"charitydata.xls.\" A charitable organization has enlisted your expertise to understand patterns and forecast potential donations from their recent marketing initiative. This dataset encompasses information on 8009 prospective donors, detailing twenty predictor variables alongside one outcome variable. The response variable, `damt`, represents the donation amount in dollars. Your task is to utilize this data to assist the charity in predicting the donation amounts from individuals.\n",
        "\n",
        "## Data Description\n",
        "\n",
        "* **`ID`**: Donor identifier\n",
        "* **`reg1`**: Donor belongs to region 1\n",
        "* **`reg2`**: Donor belongs to region 2\n",
        "* **`reg3`**: Donor belongs to region 3\n",
        "* **`reg4`**: Donor belongs to region 4\n",
        "* **`home`**: 1= homeowner, 0=not a homeowner\n",
        "* **`kids`**: number of children\n",
        "* **`hinc`**: Household income with 7 categories, 1= lowest income category, 7=Highest income category\n",
        "* **`genf`**: Gender (0=Male, 1=Female)\n",
        "* **`wrat`**: Wealth rating with 9 being the highest and 0 being the lowest\n",
        "* **`avhv`**: Average home value in donor's neighborhood in 1,000 USDs.\n",
        "* **`incm`**: Median family income in donor's neighborhood in 1,000 USDs.\n",
        "* **`inca`**: Average family income in donor's neighborhood in 1,000 USDs.\n",
        "* **`plow`**: Percentage categorize as low income in donor's neighborhood\n",
        "* **`npro`**: Lifetime number of promotions received to date\n",
        "* **`tgif`**: Dollar amount of lifetime gifts to date\n",
        "* **`lgif`**: Dollar amount of largest gifts to date\n",
        "* **`rgif`**: Dollar amount of most recent gift\n",
        "* **`tdon`**: Numbers of months since last denotion\n",
        "* **`tlag`**: Numbers of months between first and second gift\n",
        "* **`agif`**: Average dollar amount of gifts to date\n",
        "* **`damt`**: Dollar amount of donation in 1,000 USDs (Target variable)\n",
        "* **`Validation`**: Training= training data, Validation= Validation data  (data identifier)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "V_lwiu-QuCL0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read data in Google Colab"
      ],
      "metadata": {
        "id": "pH_k8E8hRaAY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "from google.colab import data_table\n",
        "data_table.enable_dataframe_formatter()\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "charitydata=pd.read_csv('/content/gdrive/MyDrive/DATA/charitydata.csv') # update the code  for the correct path file\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbYPO394Q3gQ",
        "outputId": "156f5cb8-74ea-4ace-9cf1-1ae7166cb583"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Call the necessary packages\n"
      ],
      "metadata": {
        "id": "WhuJWIT0pFOJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LinearRegression, RidgeCV, LassoCV, ElasticNetCV\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from mlxtend.feature_selection import SequentialFeatureSelector\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the dataset\n",
        "charitydata = pd.read_csv(\"/content/charitydata.csv\")\n",
        "\n",
        "charitydata.head()"
      ],
      "metadata": {
        "id": "40eM9QSs6euI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "24114df3-33e5-415a-c7a2-a30ab279dd2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   ID  reg1  reg2  reg3  reg4  home  kids  hinc  genf  wrat  ...  npro  tgif  \\\n",
              "0   1     0     0     1     0     1     1     4     1     8  ...    20    81   \n",
              "1   2     0     0     1     0     1     2     4     0     8  ...    95   156   \n",
              "2   5     0     0     1     0     1     0     4     1     4  ...    85   132   \n",
              "3   6     0     1     0     0     1     1     5     0     9  ...    83   131   \n",
              "4   7     0     0     0     0     1     3     4     0     8  ...    50    74   \n",
              "\n",
              "   lgif  rgif  tdon  tlag   agif  donr  damt  Validation  \n",
              "0    81    19    17     6  21.05     0     0    Training  \n",
              "1    16    17    19     3  13.26     1    15    Training  \n",
              "2    15    10    10     6  12.07     1    17  Validation  \n",
              "3     5     3    13     4   4.12     1    12    Training  \n",
              "4     6     5    22     3   6.50     0     0    Training  \n",
              "\n",
              "[5 rows x 24 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fb7ad0d0-27e3-42d7-8384-f7aa8e6bee9d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>reg1</th>\n",
              "      <th>reg2</th>\n",
              "      <th>reg3</th>\n",
              "      <th>reg4</th>\n",
              "      <th>home</th>\n",
              "      <th>kids</th>\n",
              "      <th>hinc</th>\n",
              "      <th>genf</th>\n",
              "      <th>wrat</th>\n",
              "      <th>...</th>\n",
              "      <th>npro</th>\n",
              "      <th>tgif</th>\n",
              "      <th>lgif</th>\n",
              "      <th>rgif</th>\n",
              "      <th>tdon</th>\n",
              "      <th>tlag</th>\n",
              "      <th>agif</th>\n",
              "      <th>donr</th>\n",
              "      <th>damt</th>\n",
              "      <th>Validation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>...</td>\n",
              "      <td>20</td>\n",
              "      <td>81</td>\n",
              "      <td>81</td>\n",
              "      <td>19</td>\n",
              "      <td>17</td>\n",
              "      <td>6</td>\n",
              "      <td>21.05</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>...</td>\n",
              "      <td>95</td>\n",
              "      <td>156</td>\n",
              "      <td>16</td>\n",
              "      <td>17</td>\n",
              "      <td>19</td>\n",
              "      <td>3</td>\n",
              "      <td>13.26</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>85</td>\n",
              "      <td>132</td>\n",
              "      <td>15</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>6</td>\n",
              "      <td>12.07</td>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>Validation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>...</td>\n",
              "      <td>83</td>\n",
              "      <td>131</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>13</td>\n",
              "      <td>4</td>\n",
              "      <td>4.12</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>...</td>\n",
              "      <td>50</td>\n",
              "      <td>74</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>22</td>\n",
              "      <td>3</td>\n",
              "      <td>6.50</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 24 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fb7ad0d0-27e3-42d7-8384-f7aa8e6bee9d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fb7ad0d0-27e3-42d7-8384-f7aa8e6bee9d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fb7ad0d0-27e3-42d7-8384-f7aa8e6bee9d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3212400e-706f-4986-8a25-fcafe89105a1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3212400e-706f-4986-8a25-fcafe89105a1')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3212400e-706f-4986-8a25-fcafe89105a1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "charitydata"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 1: Data Preprocessing and Inspection\n",
        "\n",
        "* **1A**: Verify the Data Types. Implement Python code to ensure the accuracy of each variable's data type. Within the Word document for Task 1, section 1A, document your process. (i.e., `reg1` was originally an int64, which I converted to a categorical type; `Validation` was noted as an object, and I altered its type to categorical)\n",
        "\n",
        "* **1B**: Calculate the percentage of missing values in the `charitydata` dataset and identify only those variables that have missing data, along with their respective percentages of missingness. Document these findings in the Word document under Task 1, section 1B (i.e.,`genf` has 4% missingness and `home` has 44% missingness)\n",
        "\n",
        "* **1C**: Generate a new dataframe named `traindata` from the `charitydata` dataset, filtering for rows where `Validation` equals `Training`. Subsequently, remove the `ID` and `Validation` columns from `traindata`. Similarly, create another dataframe named `testdata` from `charitydata`, selecting rows where `Validation` equals `Validation, and then eliminate the `ID` and `Validation` columns from \"testdata\". Determine the total count of rows and columns present in both `traindata` and `testdata`, and document these figures within the Word document under Task 1, section 1C (i.e. traindata has 3456 rows and 99 columns, testdata has 3245 rows and 99 columns).\n",
        "\n",
        "* **1D**: Separate both 'traindata' and 'testdata' into their respective predictors and target variables, labeling them as 'X_train' and 'y_train' for the training data, and 'X_test' and 'y_test' for the test data. Determine the total count of rows and columns present in both 'X_train' and 'X_test', and document these figures within the Word document under Task 1, section 1D (i.e. X_train has 3456 rows and 99 columns, X_test has 3245 rows and 99 columns).\n",
        "\n",
        "\n",
        "* **1E**: Next, utilize Scikit-learn to preprocess the data in the following manner: For both 'X_train' and 'X_test', fill in missing values using the median for numerical variables and the most common value for categorical variables. Following this, implement one-hot encoding to transform the categorical variables. Please use OneHotEncoder(drop='first') to drop the first category from each categorical feature. Save the preprocessed data as X_train_processed, and X_test_processed. Determine the total count of rows and columns present in both 'X_train_processed' and 'X_test_processed', and document these figures within the Word document under Task 1, section 1E (i.e. X_train_processed has 3456 rows and 99 columns, X_test_processed has 3245 rows and 99 columns).\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "W7MUDK5kjsqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Place all the code related to Task 1 within the following code block:"
      ],
      "metadata": {
        "id": "sDz56son_t5a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 1: Data Preprocessing and Inspection\n",
        "1A: Verify the Data Types"
      ],
      "metadata": {
        "id": "0hvVpiCVdL-_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# data types to confirm the conversion\n",
        "print(charitydata.dtypes)"
      ],
      "metadata": {
        "id": "A8KVS25f9Ei6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86447ead-eeaf-4106-b11f-cc0eee6d4444"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ID              int64\n",
            "reg1            int64\n",
            "reg2            int64\n",
            "reg3            int64\n",
            "reg4            int64\n",
            "home            int64\n",
            "kids            int64\n",
            "hinc            int64\n",
            "genf            int64\n",
            "wrat            int64\n",
            "avhv          float64\n",
            "incm          float64\n",
            "inca            int64\n",
            "plow            int64\n",
            "npro            int64\n",
            "tgif            int64\n",
            "lgif            int64\n",
            "rgif            int64\n",
            "tdon            int64\n",
            "tlag            int64\n",
            "agif          float64\n",
            "donr            int64\n",
            "damt            int64\n",
            "Validation     object\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(charitydata.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDlyOc09tjzc",
        "outputId": "f86692d2-485b-4ccc-99e6-66adc165977d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['ID', 'reg1', 'reg2', 'reg3', 'reg4', 'home', 'kids', 'hinc', 'genf',\n",
            "       'wrat', 'avhv', 'incm', 'inca', 'plow', 'npro', 'tgif', 'lgif', 'rgif',\n",
            "       'tdon', 'tlag', 'agif', 'donr', 'damt', 'Validation'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1B: Calculate the percentage of missing value"
      ],
      "metadata": {
        "id": "UDyU8HuXdg-4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "missing_percentages = charitydata.isnull().mean() * 100\n",
        "missing_percentages[missing_percentages > 0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YajzNaq2dgt0",
        "outputId": "9d850cb3-1027-49b8-b173-9e339a7d4774"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "avhv    0.083306\n",
              "incm    0.083306\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "missing_percentages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vo0Fm1mnemf",
        "outputId": "20a91389-ce9f-45b5-f7a9-4d87ef80f66f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ID            0.000000\n",
              "reg1          0.000000\n",
              "reg2          0.000000\n",
              "reg3          0.000000\n",
              "reg4          0.000000\n",
              "home          0.000000\n",
              "kids          0.000000\n",
              "hinc          0.000000\n",
              "genf          0.000000\n",
              "wrat          0.000000\n",
              "avhv          0.083306\n",
              "incm          0.083306\n",
              "inca          0.000000\n",
              "plow          0.000000\n",
              "npro          0.000000\n",
              "tgif          0.000000\n",
              "lgif          0.000000\n",
              "rgif          0.000000\n",
              "tdon          0.000000\n",
              "tlag          0.000000\n",
              "agif          0.000000\n",
              "donr          0.000000\n",
              "damt          0.000000\n",
              "Validation    0.000000\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1C: Generate traindata and testdata"
      ],
      "metadata": {
        "id": "vwkhua6gdn_8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "traindata = charitydata[charitydata['Validation'] == 'Training'].copy()\n",
        "traindata.drop(columns=['ID', 'Validation'], inplace=True)\n",
        "\n",
        "testdata = charitydata[charitydata['Validation'] == 'Validation'].copy()\n",
        "testdata.drop(columns=['ID', 'Validation'], inplace=True)\n",
        "\n",
        "print(\"traindata:\", traindata.shape)\n",
        "print(\"testdata:\", testdata.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-O-jRi-6dnut",
        "outputId": "5b050207-e086-46c9-8496-058eec89be22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "traindata: (4501, 22)\n",
            "testdata: (1501, 22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1D: Separate predictors and target variables"
      ],
      "metadata": {
        "id": "-MaxmAVOd1FE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = traindata.drop(columns=['damt'])\n",
        "y_train = traindata['damt']\n",
        "\n",
        "X_test = testdata.drop(columns=['damt'])\n",
        "y_test = testdata['damt']\n",
        "\n",
        "# 1E: Preprocess the data\n",
        "numerical_features = X_train.select_dtypes(include=['float64', 'int64']).columns\n",
        "categorical_features = X_train.select_dtypes(include=['object']).columns\n",
        "\n",
        "numerical_transformer = SimpleImputer(strategy='median')\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(drop='first'))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numerical_transformer, numerical_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ])\n",
        "\n",
        "pipeline = Pipeline(steps=[('preprocessor', preprocessor)])\n",
        "\n",
        "X_train_processed = pipeline.fit_transform(X_train)\n",
        "X_test_processed = pipeline.transform(X_test)"
      ],
      "metadata": {
        "id": "Adc_1cDSd4Jj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Output the shapes\n",
        "print(\"Processed Training Data Shape:\", X_train_processed.shape)\n",
        "print(\"Processed Test Data Shape:\", X_test_processed.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rsTHX65d9-l",
        "outputId": "9017c794-a7cc-4b3b-9303-bf92451b3fd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed Training Data Shape: (4501, 21)\n",
            "Processed Test Data Shape: (1501, 21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TASK 2\n",
        "\n",
        "Employ the `X_train_processed` dataset to identify the optimal linear regression model by applying two distinct methods: forward stepwise selection and backward stepwise selection, each evaluated using Mallow's Cp criterion with 5-fold cross validation. Students can use `SequentialFeatureSelector` module from `mlxtend` package to implement subset selection, as shown in Module 4 practice lab. Set the cross validation parameter (n_splits=5)  to 5 and use `random_state=5410` to have comparable results.\n",
        "\n",
        "* **2A**: Within the Word document under Task 2, section 2A, list the features that are selected based on forward selection method.\n",
        "\n",
        "* **2B**: Within the Word document under Task 2, section 2B, list the features that are selected based on forward selection method.\n",
        "\n",
        "* **2C**: Discuss the implications for the bias-variance trade-off among the model generated through forward/backward selection methods and the full model with all potential features. Specifically, contemplate whether there's a reduction or an increase in bias and variance. Provide your answer in a brief paragraph under Task 2, section 2C in your Word Document template.\n",
        "\n",
        "* **2D**: Estimate the expected test error for both the forward stepwise and backward stepwise regression models previously determined in Task 2. It's important to note that this estimation must be derived exclusively from the `X_train_processed` dataset. Document your findings within Task 2, section 2D in your Word Document template.\n",
        "\n",
        "\n",
        "* **2E**: Estimate the expected test error for both the forward stepwise and backward stepwise regression models previously determined in Task 2. It's important to note that this estimation must be derived exclusively from the `X_train_processed` dataset. Document your findings within Task 2, section 2D in your Word Document template.\n"
      ],
      "metadata": {
        "id": "IW8pawkFTRF0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Place all the code related to Task 2 within the following code block:"
      ],
      "metadata": {
        "id": "nTJMeLAliG44"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 2: Forward and Backward Stepwise Selection"
      ],
      "metadata": {
        "id": "GEPxkj7tewvq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2A: Forward Stepwise Selection\n",
        "forward_selector = SequentialFeatureSelector(LinearRegression(),\n",
        "                                             k_features='best',\n",
        "                                             forward=True,\n",
        "                                             scoring='neg_mean_squared_error',\n",
        "                                             cv=5,\n",
        "                                             n_jobs=-1)\n",
        "\n",
        "forward_selector.fit(X_train_processed, y_train)\n",
        "selected_forward_features = list(X_train.columns[list(forward_selector.k_feature_idx_)])"
      ],
      "metadata": {
        "id": "42STi88eiB_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2B: Backward Stepwise Selection\n",
        "backward_selector = SequentialFeatureSelector(LinearRegression(),\n",
        "                                              k_features='best',\n",
        "                                              forward=False,\n",
        "                                              scoring='neg_mean_squared_error',\n",
        "                                              cv=5,\n",
        "                                              n_jobs=-1)\n",
        "\n",
        "backward_selector.fit(X_train_processed, y_train)\n",
        "selected_backward_features = list(X_train.columns[list(backward_selector.k_feature_idx_)])"
      ],
      "metadata": {
        "id": "ZhUCzYLoe300"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the selected features\n",
        "\n",
        "print(\"Features selected based on forward selection method:\")\n",
        "print(selected_forward_features)\n",
        "\n",
        "print(\"Features selected based on forward selection method:\")\n",
        "print(selected_backward_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKoZDXKde9m1",
        "outputId": "19f46f65-f073-4103-b9e5-97be54d7c856"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features selected based on forward selection method:\n",
            "['reg1', 'reg2', 'reg3', 'reg4', 'home', 'kids', 'hinc', 'incm', 'plow', 'npro', 'tgif', 'rgif', 'tdon', 'agif', 'donr']\n",
            "Features selected based on forward selection method:\n",
            "['reg1', 'reg2', 'reg3', 'reg4', 'home', 'kids', 'hinc', 'incm', 'plow', 'npro', 'tgif', 'rgif', 'tdon', 'agif', 'donr']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TASK 3\n",
        "In this task, we will explore whether regularization can enhance our model's performance.\n",
        "\n",
        "* Adjust the `X_train_processed` and `X_test_processed` datasets by incorporating standardization for the numerical variables within your pipeline, utilizing the `StandardScaler()` from Scikit-learn. Label the resulting datasets as `X_train_scaled_processed` and `X_test_scaled_processed`, respectively.\n",
        "\n",
        "* **3A**: Fit a ridge regression model on `X_train_scaled_processed` using Scikit-learn's `RidgeCV`, selecting the λ parameter that minimizes the error from 5-fold cross-validation. Choose the λ values from a range spanning 600 points, distributed logarithmically between $10^{-1}$ and $10^{1}$  (i.e., `lambdas=np.logspace(-1, 1, 600)`). Enter the optimal lamda under Task 3, section 3A in your Word Document template.\n",
        "\n",
        "\n",
        "* **3B**: Fit a lasso regression model on `X_train_scaled_processed` using Scikit-learn's `LassoCV`, selecting the λ parameter that minimizes the error from 5-fold cross-validation. Choose the λ values from a range spanning 1000 points, distributed logarithmically between $10^{-4}$ and $10^{4}$  (i.e., `lambdas=np.logspace(-4, 4, 1000)`). Use `random_state=5410` to get comparable results.  Enter the optimal lamda under Task 3, section 3B in your Word Document template.\n",
        "\n",
        "* **3C**: Identify the features selected via Lasso regression by listing the variables that have non-zero coefficient estimates from the trained model. Document these variables in your Word Document template under Task 3, section 3C.\n",
        "\n",
        "* **3D**: Fit an ElasticNet regression model on `X_train_scaled_processed` using Scikit-learn's `ElasticNetCV`, selecting the λ parameter that minimizes the error from 5-fold cross-validation. Choose the λ values from a range spanning 600 points, distributed logarithmically between $10^{-1}$ and $10^{1}$  (i.e., `lambdas=np.logspace(-1, 1, 600)`).\n",
        "Also, explore a finer mix between L1 and L2 regularization by using the following ranges: `l1_ratios = np.linspace(0.1, 0.9, 9)`.\n",
        "Enter the optimal lamda and pptimal `l1_ratio` under Task 3, section 3D in your Word Document template.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0y9HOzTdFmmu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 3: Regularization"
      ],
      "metadata": {
        "id": "fRL3c83lfKu6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3A: Ridge Regression\n",
        "ridge_cv = RidgeCV(alphas=np.logspace(-1, 1, 600), cv=5)\n",
        "ridge_cv.fit(X_train_processed, y_train)\n",
        "optimal_ridge_alpha = ridge_cv.alpha_"
      ],
      "metadata": {
        "id": "Injz9kFvfKFI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3B: Lasso Regression\n",
        "lasso_cv = LassoCV(alphas=np.logspace(-4, 4, 1000), cv=5, random_state=5410)\n",
        "lasso_cv.fit(X_train_processed, y_train)\n",
        "optimal_lasso_alpha = lasso_cv.alpha_"
      ],
      "metadata": {
        "id": "A7Dp9lqUfRZ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3C: Features selected by Lasso\n",
        "lasso_selected_features = X_train.columns[lasso_cv.coef_ != 0]"
      ],
      "metadata": {
        "id": "bYaTJsXKfemh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3D: ElasticNet Regression\n",
        "elasticnet_cv = ElasticNetCV(alphas=np.logspace(-1, 1, 600), l1_ratio=np.linspace(0.1, 0.9, 9), cv=5)\n",
        "elasticnet_cv.fit(X_train_processed, y_train)\n",
        "optimal_elasticnet_alpha = elasticnet_cv.alpha_\n",
        "optimal_elasticnet_l1_ratio = elasticnet_cv.l1_ratio_"
      ],
      "metadata": {
        "id": "HVTjwaNMfhpf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4E: Report the results in a dictionary\n",
        "results = {\n",
        "    'Full Linear Regression': optimal_ridge_alpha,\n",
        "    'Ridge Regression': optimal_ridge_alpha,\n",
        "    'Lasso Regression': optimal_lasso_alpha,\n",
        "    'ElasticNet Regression': optimal_elasticnet_l1_ratio\n",
        "}\n",
        "\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Htn8zWx9foQU",
        "outputId": "8c7629ee-2d75-4bb4-b6c7-71ea2f778928"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Full Linear Regression': 0.11136393657225817, 'Ridge Regression': 0.11136393657225817, 'Lasso Regression': 0.0005354620899273607, 'ElasticNet Regression': 0.9}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Place all the code related to Task 3 within the following code block:"
      ],
      "metadata": {
        "id": "t1rA7LJTOX0t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TASK 4\n",
        "\n",
        "* **4A**: Now it's time to assess our models. As a benchmark, take the full linear regression model which takes all predictors as input, trained on the `X_trained_processed` dataset. Then calculate the Mean Squared Prediction Error (MSPE) on the test data and enter your finding under Task 4, section 4A.\n",
        "\n",
        "\n",
        "* **4B**: Calculate the Mean Squared Prediction Error (MSPE) on the test data for the model identified through forward selection in Task 2. Document your findings under Task 4, section 4B.\n",
        "\n",
        "* **4C**: Calculate the Mean Squared Prediction Error (MSPE) on the test data for the model identified through backward selection in Task 2. Document your findings under Task 4, section 4C.\n",
        "\n",
        "* **4D**: Compute the Mean Squared Prediction Error (MSPE) for the test dataset using the model refined with the optimal lambda value obtained from Ridge Regression in Task 4. Record your analysis in Task 4, section 4D.\n",
        "\n",
        "* **4E**: Compute the Mean Squared Prediction Error (MSPE) for the test dataset using the model refined with the optimal lambda value obtained from Ridge Regression in Task 4. Record your analysis in Task 4, section 4D.\n",
        "\n",
        "* **4F**: Compute the Mean Squared Prediction Error (MSPE) for the test dataset using the model refined with the optimal lambda value obtained from Lasso Regression in Task 4. Record your analysis in Task 4, section 4F.\n",
        "\n",
        "* **4G**: Compute the Mean Squared Prediction Error (MSPE) for the test dataset using the model refined with the optimal `lambda` and the `l1_ratio` valuea obtained from ElasticNet Regression in Task 4. Record your analysis in Task 4, section 4G.\n",
        "\n",
        "\n",
        "* **4H**: Evaluate which model performed well on the test dataset. Are the differences in MSPEs significant? As a data scientist aiming to maximize donations for the company, decide which of the models explored in this lab you would recommend for production use. Provide detailed justification for your choice to fully address this question.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-LHockeKcR_8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Place all the code related to Task 4 within the following code block:"
      ],
      "metadata": {
        "id": "WTTUfYbZiOLn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 4: Model Assessment"
      ],
      "metadata": {
        "id": "Wjs6UFxff3sP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4A: Full Linear Regression Model\n",
        "full_linear_model = LinearRegression()\n",
        "full_linear_model.fit(X_train_processed, y_train)\n",
        "full_linear_mspe = mean_squared_error(y_test, full_linear_model.predict(X_test_processed))"
      ],
      "metadata": {
        "id": "Y05iwM8uiQVD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4B: Forward Stepwise Regression Model\n",
        "forward_model = LinearRegression().fit(forward_selector.transform(X_train_processed), y_train)\n",
        "forward_mspe = mean_squared_error(y_test, forward_model.predict(forward_selector.transform(X_test_processed)))\n"
      ],
      "metadata": {
        "id": "bNF_Imi6f8dE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4C: Backward Stepwise Regression Model\n",
        "backward_model = LinearRegression().fit(backward_selector.transform(X_train_processed), y_train)\n",
        "backward_mspe = mean_squared_error(y_test, backward_model.predict(backward_selector.transform(X_test_processed)))"
      ],
      "metadata": {
        "id": "E-g8Q-Bof_D8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4D: Ridge Regression Model\n",
        "ridge_model = RidgeCV(alphas=[optimal_ridge_alpha], cv=5)\n",
        "ridge_model.fit(X_train_processed, y_train)\n",
        "ridge_mspe = mean_squared_error(y_test, ridge_model.predict(X_test_processed))"
      ],
      "metadata": {
        "id": "rLMeJxIXgBeb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4E: Lasso Regression Model\n",
        "lasso_model = LassoCV(alphas=[optimal_lasso_alpha], cv=5, random_state=5410)\n",
        "lasso_model.fit(X_train_processed, y_train)\n",
        "lasso_mspe = mean_squared_error(y_test, lasso_model.predict(X_test_processed))"
      ],
      "metadata": {
        "id": "YFBdPH2AgEHU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4F: ElasticNet Regression Model\n",
        "elasticnet_model = ElasticNetCV(alphas=[optimal_elasticnet_alpha], l1_ratio=[optimal_elasticnet_l1_ratio], cv=5)\n",
        "elasticnet_model.fit(X_train_processed, y_train)\n",
        "elasticnet_mspe = mean_squared_error(y_test, elasticnet_model.predict(X_test_processed))"
      ],
      "metadata": {
        "id": "sTdbuCLPgG5M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4G: Report the results in a dictionary\n",
        "results = {\n",
        "    'Full Linear Regression': full_linear_mspe,\n",
        "    'Forward Stepwise Regression': forward_mspe,\n",
        "    'Backward Stepwise Regression': backward_mspe,\n",
        "    'Ridge Regression': ridge_mspe,\n",
        "    'Lasso Regression': lasso_mspe,\n",
        "    'ElasticNet Regression': elasticnet_mspe\n",
        "}\n",
        "\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4CiqS_ggJ17",
        "outputId": "781db517-df1a-439f-b6f8-e78703f45e21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Full Linear Regression': 1.360144566310689, 'Forward Stepwise Regression': 1.3580207207498007, 'Backward Stepwise Regression': 1.3580207207498007, 'Ridge Regression': 1.3601953134316536, 'Lasso Regression': 1.36057107680069, 'ElasticNet Regression': 1.770489446253324}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4H: Model Recommendation\n",
        "best_model = min(results, key=results.get)\n",
        "\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsVqUyGzgS0a",
        "outputId": "aa1b4014-d0ad-458b-ad8e-261c6268fb01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Full Linear Regression': 1.360144566310689, 'Forward Stepwise Regression': 1.3580207207498007, 'Backward Stepwise Regression': 1.3580207207498007, 'Ridge Regression': 1.3601953134316536, 'Lasso Regression': 1.36057107680069, 'ElasticNet Regression': 1.770489446253324}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LinearRegression, RidgeCV, LassoCV, ElasticNetCV\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from mlxtend.feature_selection import SequentialFeatureSelector\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the dataset\n",
        "charitydata = pd.read_csv(\"/content/charitydata.csv\")\n",
        "\n",
        "# Task 1: Data Preprocessing and Inspection\n",
        "\n",
        "# 1A: Verify the Data Types\n",
        "charitydata.dtypes\n",
        "\n",
        "# 1B: Calculate the percentage of missing values\n",
        "missing_percentages = charitydata.isnull().mean() * 100\n",
        "\n",
        "# 1C: Generate traindata and testdata\n",
        "traindata = charitydata[charitydata['Validation'] == 'Training'].copy()\n",
        "traindata.drop(columns=['ID', 'Validation'], inplace=True)\n",
        "\n",
        "testdata = charitydata[charitydata['Validation'] == 'Validation'].copy()\n",
        "testdata.drop(columns=['ID', 'Validation'], inplace=True)\n",
        "\n",
        "# 1D: Separate predictors and target variables\n",
        "X_train = traindata.drop(columns=['damt'])\n",
        "y_train = traindata['damt']\n",
        "\n",
        "X_test = testdata.drop(columns=['damt'])\n",
        "y_test = testdata['damt']\n",
        "\n",
        "# 1E: Preprocess the data\n",
        "numerical_features = X_train.select_dtypes(include=['float64', 'int64']).columns\n",
        "categorical_features = X_train.select_dtypes(include=['object']).columns\n",
        "\n",
        "numerical_transformer = SimpleImputer(strategy='median')\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(drop='first'))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numerical_transformer, numerical_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ])\n",
        "\n",
        "pipeline = Pipeline(steps=[('preprocessor', preprocessor)])\n",
        "\n",
        "X_train_processed = pipeline.fit_transform(X_train)\n",
        "X_test_processed = pipeline.transform(X_test)\n",
        "\n",
        "# Task 2: Forward and Backward Stepwise Selection\n",
        "\n",
        "# 2A: Forward Stepwise Selection\n",
        "forward_selector = SequentialFeatureSelector(LinearRegression(),\n",
        "                                             k_features='best',\n",
        "                                             forward=True,\n",
        "                                             scoring='neg_mean_squared_error',\n",
        "                                             cv=5,\n",
        "                                             n_jobs=-1)\n",
        "\n",
        "forward_selector.fit(X_train_processed, y_train)\n",
        "selected_forward_features = list(X_train.columns[list(forward_selector.k_feature_idx_)])\n",
        "\n",
        "# 2B: Backward Stepwise Selection\n",
        "backward_selector = SequentialFeatureSelector(LinearRegression(),\n",
        "                                              k_features='best',\n",
        "                                              forward=False,\n",
        "                                              scoring='neg_mean_squared_error',\n",
        "                                              cv=5,\n",
        "                                              n_jobs=-1)\n",
        "\n",
        "backward_selector.fit(X_train_processed, y_train)\n",
        "selected_backward_features = list(X_train.columns[list(backward_selector.k_feature_idx_)])\n",
        "\n",
        "# Task 3: Regularization\n",
        "\n",
        "# 3A: Ridge Regression\n",
        "ridge_cv = RidgeCV(alphas=np.logspace(-1, 1, 600), cv=5)\n",
        "ridge_cv.fit(X_train_processed, y_train)\n",
        "optimal_ridge_alpha = ridge_cv.alpha_\n",
        "\n",
        "# 3B: Lasso Regression\n",
        "lasso_cv = LassoCV(alphas=np.logspace(-4, 4, 1000), cv=5, random_state=5410)\n",
        "lasso_cv.fit(X_train_processed, y_train)\n",
        "optimal_lasso_alpha = lasso_cv.alpha_\n",
        "\n",
        "# 3C: Features selected by Lasso\n",
        "lasso_selected_features = X_train.columns[lasso_cv.coef_ != 0]\n",
        "\n",
        "# 3D: ElasticNet Regression\n",
        "elasticnet_cv = ElasticNetCV(alphas=np.logspace(-1, 1, 600), l1_ratio=np.linspace(0.1, 0.9, 9), cv=5)\n",
        "elasticnet_cv.fit(X_train_processed, y_train)\n",
        "optimal_elasticnet_alpha = elasticnet_cv.alpha_\n",
        "optimal_elasticnet_l1_ratio = elasticnet_cv.l1_ratio_\n",
        "\n",
        "# Task 4: Model Assessment\n",
        "\n",
        "# 4A: Full Linear Regression Model\n",
        "full_linear_model = LinearRegression()\n",
        "full_linear_model.fit(X_train_processed, y_train)\n",
        "full_linear_mspe = mean_squared_error(y_test, full_linear_model.predict(X_test_processed))\n",
        "\n",
        "# 4B: Forward Stepwise Regression Model\n",
        "forward_model = LinearRegression().fit(forward_selector.transform(X_train_processed), y_train)\n",
        "forward_mspe = mean_squared_error(y_test, forward_model.predict(forward_selector.transform(X_test_processed)))\n",
        "\n",
        "# 4C: Backward Stepwise Regression Model\n",
        "backward_model = LinearRegression().fit(backward_selector.transform(X_train_processed), y_train)\n",
        "backward_mspe = mean_squared_error(y_test, backward_model.predict(backward_selector.transform(X_test_processed)))\n",
        "\n",
        "# 4D: Ridge Regression Model\n",
        "ridge_model = RidgeCV(alphas=[optimal_ridge_alpha], cv=5)\n",
        "ridge_model.fit(X_train_processed, y_train)\n",
        "ridge_mspe = mean_squared_error(y_test, ridge_model.predict(X_test_processed))\n",
        "\n",
        "# 4E: Lasso Regression Model\n",
        "lasso_model = LassoCV(alphas=[optimal_lasso_alpha], cv=5, random_state=5410)\n",
        "lasso_model.fit(X_train_processed, y_train)\n",
        "lasso_mspe = mean_squared_error(y_test, lasso_model.predict(X_test_processed))\n",
        "\n",
        "# 4F: ElasticNet Regression Model\n",
        "elasticnet_model = ElasticNetCV(alphas=[optimal_elasticnet_alpha], l1_ratio=[optimal_elasticnet_l1_ratio], cv=5)\n",
        "elasticnet_model.fit(X_train_processed, y_train)\n",
        "elasticnet_mspe = mean_squared_error(y_test, elasticnet_model.predict(X_test_processed))\n",
        "\n",
        "# 4G: Report the results in a dictionary\n",
        "results = {\n",
        "    'Full Linear Regression': full_linear_mspe,\n",
        "    'Forward Stepwise Regression': forward_mspe,\n",
        "    'Backward Stepwise Regression': backward_mspe,\n",
        "    'Ridge Regression': ridge_mspe,\n",
        "    'Lasso Regression': lasso_mspe,\n",
        "    'ElasticNet Regression': elasticnet_mspe\n",
        "}\n",
        "\n",
        "# 4H: Model Recommendation\n",
        "best_model = min(results, key=results.get)\n",
        "\n",
        "print(results)"
      ],
      "metadata": {
        "id": "Af_IcFXAgXh6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8aaabe2-2d8f-47a0-f074-c4bc5d8981f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Full Linear Regression': 1.360144566310689, 'Forward Stepwise Regression': 1.3580207207498007, 'Backward Stepwise Regression': 1.3580207207498007, 'Ridge Regression': 1.3601953134316536, 'Lasso Regression': 1.36057107680069, 'ElasticNet Regression': 1.770489446253324}\n"
          ]
        }
      ]
    }
  ]
}